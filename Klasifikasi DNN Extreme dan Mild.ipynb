{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss Function\n",
    "def focal_loss(gamma=3.0, alpha=0.5):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        focal_loss = -y_true * (alpha * tf.math.pow(1 - y_pred, gamma) * tf.math.log(y_pred))\n",
    "        return tf.reduce_sum(focal_loss, axis=-1)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model with ReLU activation\n",
    "def create_mlp_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# Load dataset hasil oversampling ADASYN_Extreme\n",
    "file_path_oversampled_extreme = 'D:\\Tugas Akhir\\Stroke\\data_oversampled_extreme.csv'\n",
    "df_oversampled_extreme = pd.read_csv(file_path_oversampled_extreme)\n",
    "\n",
    "# Ganti koma dengan titik dan ubah tipe data ke float32 untuk kolom tertentu\n",
    "columns_to_convert = ['age', 'avg_glucose_level', 'bmi']\n",
    "df_oversampled_extreme[columns_to_convert] = df_oversampled_extreme[columns_to_convert].replace(',', '.', regex=True).astype('float32')\n",
    "\n",
    "# Pisahkan fitur dan target untuk dataset hasil oversampling ADASYN_Extreme\n",
    "X_oversampled_extreme = df_oversampled_extreme.drop('stroke', axis=1)\n",
    "y_oversampled_extreme = df_oversampled_extreme['stroke']\n",
    "\n",
    "# Mengonversi target menjadi one-hot encoding untuk ADASYN_Extreme\n",
    "y_oversampled_one_hot_extreme = tf.keras.utils.to_categorical(y_oversampled_extreme, num_classes)\n",
    "\n",
    "# Pastikan tipe data float32 untuk fitur\n",
    "X_oversampled_extreme = X_oversampled_extreme.astype('float32')\n",
    "\n",
    "\n",
    "# Load dataset hasil PCA-KMeans_Extreme\n",
    "file_path_pca_kmeans_extreme = 'D:/Tugas Akhir/Stroke/data_hasil_nearmiss_extreme.csv'\n",
    "df_pca_kmeans_extreme = pd.read_csv(file_path_pca_kmeans_extreme)\n",
    "\n",
    "# Pisahkan fitur dan target untuk dataset hasil PCA-KMeans_Extreme\n",
    "X_pca_kmeans_extreme = df_pca_kmeans_extreme.drop(['stroke', 'Cluster'], axis=1)\n",
    "y_pca_kmeans_extreme = df_pca_kmeans_extreme['stroke']\n",
    "\n",
    "# Mengonversi target menjadi one-hot encoding untuk PCA-KMeans_Extreme\n",
    "y_pca_kmeans_one_hot_extreme = tf.keras.utils.to_categorical(y_pca_kmeans_extreme, num_classes)\n",
    "\n",
    "# Pastikan tipe data float32 untuk fitur\n",
    "X_pca_kmeans_extreme = X_pca_kmeans_extreme.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7368</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5491</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5182</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5251</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5730</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5251</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5731 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender     age  hypertension  heart_disease  ever_married  \\\n",
       "0          0  0.7368             0              1             1   \n",
       "1          1  0.9474             1              0             1   \n",
       "2          0  0.8596             1              1             1   \n",
       "3          1  0.9825             1              0             1   \n",
       "4          1  0.4386             1              0             1   \n",
       "...      ...     ...           ...            ...           ...   \n",
       "5726       0  0.9322             0              0             1   \n",
       "5727       0  0.9124             0              0             1   \n",
       "5728       0  0.9134             0              0             1   \n",
       "5729       0  0.9311             0              0             1   \n",
       "5730       0  0.9322             0              0             1   \n",
       "\n",
       "      work_type_Govt_job  work_type_Private  work_type_Self-employed  \\\n",
       "0                      0                  1                        0   \n",
       "1                      0                  0                        1   \n",
       "2                      0                  1                        0   \n",
       "3                      0                  1                        0   \n",
       "4                      0                  0                        1   \n",
       "...                  ...                ...                      ...   \n",
       "5726                   0                  0                        1   \n",
       "5727                   0                  0                        1   \n",
       "5728                   0                  0                        1   \n",
       "5729                   0                  0                        1   \n",
       "5730                   0                  0                        1   \n",
       "\n",
       "      Residence_type  avg_glucose_level     bmi  smoking_status_Unknown  \\\n",
       "0                  0             0.8012  0.5227                       0   \n",
       "1                  1             0.5491  0.2624                       0   \n",
       "2                  1             0.0687  0.3326                       0   \n",
       "3                  1             0.1164  0.3802                       0   \n",
       "4                  1             0.5182  0.4050                       0   \n",
       "...              ...                ...     ...                     ...   \n",
       "5726               1             0.5251  0.3395                       0   \n",
       "5727               0             0.4925  0.4394                       0   \n",
       "5728               0             0.4806  0.4331                       0   \n",
       "5729               1             0.5234  0.3450                       0   \n",
       "5730               1             0.5251  0.3395                       0   \n",
       "\n",
       "      smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                                  1                            0   \n",
       "1                                  0                            1   \n",
       "2                                  0                            1   \n",
       "3                                  0                            1   \n",
       "4                                  0                            1   \n",
       "...                              ...                          ...   \n",
       "5726                               0                            0   \n",
       "5727                               0                            0   \n",
       "5728                               0                            0   \n",
       "5729                               0                            0   \n",
       "5730                               0                            0   \n",
       "\n",
       "      smoking_status_smokes  stroke  \n",
       "0                         0       1  \n",
       "1                         0       1  \n",
       "2                         0       1  \n",
       "3                         0       1  \n",
       "4                         0       1  \n",
       "...                     ...     ...  \n",
       "5726                      0       1  \n",
       "5727                      0       1  \n",
       "5728                      0       1  \n",
       "5729                      0       1  \n",
       "5730                      0       1  \n",
       "\n",
       "[5731 rows x 16 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversampled_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>stroke</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>1.4776</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>-0.4726</td>\n",
       "      <td>1.1645</td>\n",
       "      <td>-1.4793</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>-1.2224</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>-0.2692</td>\n",
       "      <td>-0.5128</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5580</td>\n",
       "      <td>-0.5396</td>\n",
       "      <td>1.6776</td>\n",
       "      <td>-0.3919</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>-0.0305</td>\n",
       "      <td>-1.1521</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>-0.5984</td>\n",
       "      <td>-0.1249</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3382</td>\n",
       "      <td>1.5483</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>-0.6456</td>\n",
       "      <td>1.0693</td>\n",
       "      <td>-1.5518</td>\n",
       "      <td>-0.2368</td>\n",
       "      <td>-0.2153</td>\n",
       "      <td>-1.3136</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>-0.1137</td>\n",
       "      <td>-0.2689</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.3545</td>\n",
       "      <td>-0.4968</td>\n",
       "      <td>1.7308</td>\n",
       "      <td>-0.5302</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>-0.4167</td>\n",
       "      <td>-0.0653</td>\n",
       "      <td>-1.1065</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>-0.4960</td>\n",
       "      <td>-0.7621</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.4800</td>\n",
       "      <td>-0.5194</td>\n",
       "      <td>1.7212</td>\n",
       "      <td>-0.4384</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>-0.2168</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-1.0881</td>\n",
       "      <td>0.4419</td>\n",
       "      <td>-0.5802</td>\n",
       "      <td>-0.7045</td>\n",
       "      <td>0.4531</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.6072</td>\n",
       "      <td>-1.4407</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>-0.7620</td>\n",
       "      <td>-1.5520</td>\n",
       "      <td>-0.8354</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>1.1951</td>\n",
       "      <td>2.2515</td>\n",
       "      <td>-0.9046</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>-0.3301</td>\n",
       "      <td>1.9275</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-0.0660</td>\n",
       "      <td>-0.4206</td>\n",
       "      <td>2.0552</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>-0.4346</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>1.5649</td>\n",
       "      <td>1.5725</td>\n",
       "      <td>2.5932</td>\n",
       "      <td>1.1732</td>\n",
       "      <td>2.0806</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.0451</td>\n",
       "      <td>1.4449</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>-1.2067</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>2.3934</td>\n",
       "      <td>1.0336</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>-1.1068</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>-1.0349</td>\n",
       "      <td>-1.0975</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.5613</td>\n",
       "      <td>3.5270</td>\n",
       "      <td>2.6722</td>\n",
       "      <td>1.1776</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>1.4190</td>\n",
       "      <td>2.9943</td>\n",
       "      <td>-0.5556</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>-1.5516</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.7989</td>\n",
       "      <td>1.2615</td>\n",
       "      <td>-0.5687</td>\n",
       "      <td>-1.3075</td>\n",
       "      <td>0.6169</td>\n",
       "      <td>1.6748</td>\n",
       "      <td>-0.1931</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>-0.6884</td>\n",
       "      <td>-1.2204</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5908</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9  \\\n",
       "0   0.0454  1.4776  0.2833 -0.4726  1.1645 -1.4793  0.0496 -0.0434 -1.2224   \n",
       "1  -0.5580 -0.5396  1.6776 -0.3919  0.1744  0.0910  0.0103 -0.0305 -1.1521   \n",
       "2   0.3382  1.5483  0.3136 -0.6456  1.0693 -1.5518 -0.2368 -0.2153 -1.3136   \n",
       "3  -0.3545 -0.4968  1.7308 -0.5302  0.0238  0.0279 -0.4167 -0.0653 -1.1065   \n",
       "4  -0.4800 -0.5194  1.7212 -0.4384  0.0940  0.0782 -0.2168 -0.0025 -1.0881   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "71  1.6072 -1.4407  0.0553 -0.7620 -1.5520 -0.8354  0.2250  1.1951  2.2515   \n",
       "72 -0.0660 -0.4206  2.0552  0.1762 -0.4346  0.1627  0.9061  0.2003  1.5649   \n",
       "73 -0.0451  1.4449  0.3273 -1.2067  0.8030  2.3934  1.0336  0.0741 -1.1068   \n",
       "74  2.5613  3.5270  2.6722  1.1776  0.9326  0.8750  0.2209  0.1416  1.4190   \n",
       "75 -0.7989  1.2615 -0.5687 -1.3075  0.6169  1.6748 -0.1931  0.5454 -0.6884   \n",
       "\n",
       "      PC10    PC11    PC12    PC13  stroke  Cluster  \n",
       "0   0.8218 -0.2692 -0.5128  0.2727       0        1  \n",
       "1   0.2849 -0.5984 -0.1249  0.6249       0        0  \n",
       "2   0.8603 -0.1137 -0.2689  0.9716       0        1  \n",
       "3   0.5004 -0.4960 -0.7621  0.6737       0        3  \n",
       "4   0.4419 -0.5802 -0.7045  0.4531       0        1  \n",
       "..     ...     ...     ...     ...     ...      ...  \n",
       "71 -0.9046  0.2886 -0.3301  1.9275       1        3  \n",
       "72  1.5725  2.5932  1.1732  2.0806       1        4  \n",
       "73  0.8241 -1.0349 -1.0975  0.7019       1        4  \n",
       "74  2.9943 -0.5556  0.7633 -1.5516       1        1  \n",
       "75 -1.2204  0.0793  0.5426  0.5908       1        4  \n",
       "\n",
       "[76 rows x 15 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca_kmeans_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pada Normalisasi 'stroke':\n",
      "stroke\n",
      "0    3481\n",
      "1      30\n",
      "Name: count, dtype: int64\n",
      "Data Pada ADASYN Extreme 'stroke':\n",
      "stroke\n",
      "0    3481\n",
      "1    2250\n",
      "Name: count, dtype: int64\n",
      "Data Pada PCA-KMeans Extreme 'stroke':\n",
      "stroke\n",
      "0    46\n",
      "1    30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hitung frekuensi nilai unik dalam kolom 'stroke'\n",
    "stroke_counts = df_oversampled_extreme['stroke'].value_counts()\n",
    "# Tampilkan output\n",
    "print(\"Data Pada ADASYN Extreme 'stroke':\")\n",
    "print(stroke_counts)\n",
    "\n",
    "# Hitung frekuensi nilai unik dalam kolom 'stroke'\n",
    "stroke_counts = df_pca_kmeans_extreme['stroke'].value_counts()\n",
    "# Tampilkan output\n",
    "print(\"Data Pada PCA-KMeans Extreme 'stroke':\")\n",
    "print(stroke_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan data ADASYN menjadi set pelatihan dan pengujian\n",
    "X_train_oversampled_extreme, X_test_oversampled_extreme, y_train_oversampled_extreme, y_test_oversampled_extreme = train_test_split(X_oversampled_extreme, y_oversampled_extreme, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pisahkan data PCA-KMeans menjadi set pelatihan dan pengujian\n",
    "X_train_pca_kmeans_extreme, X_test_pca_kmeans_extreme, y_train_pca_kmeans_extreme, y_test_pca_kmeans_extreme = train_test_split(X_pca_kmeans_extreme, y_pca_kmeans_extreme, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Latih ADASYN Extreme:\n",
      "Jumlah data latih: 4584\n",
      "Jumlah kelas 0: 2782\n",
      "Jumlah kelas 1: 1802\n",
      "\n",
      "Data Uji ADASYN Extreme:\n",
      "Jumlah data uji: 1147\n",
      "Jumlah kelas 0: 699\n",
      "Jumlah kelas 1: 448\n",
      "===========================================\n",
      "Data Latih PCA-KMeans Extreme:\n",
      "Jumlah data latih: 60\n",
      "Jumlah kelas 0: 37\n",
      "Jumlah kelas 1: 23\n",
      "\n",
      "Data Uji PCA-KMeans Extreme:\n",
      "Jumlah data uji: 16\n",
      "Jumlah kelas 0: 9\n",
      "Jumlah kelas 1: 7\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Menghitung jumlah kelas 0 dan 1 pada ADASYN (data latih)\n",
    "unique_oversampled_train, counts_oversampled_train = np.unique(y_train_oversampled_extreme, return_counts=True)\n",
    "num_class_0_oversampled_train = counts_oversampled_train[unique_oversampled_train == 0][0]\n",
    "num_class_1_oversampled_train = counts_oversampled_train[unique_oversampled_train == 1][0]\n",
    "\n",
    "# Menghitung jumlah kelas 0 dan 1 pada ADASYN (data uji)\n",
    "unique_oversampled_test, counts_oversampled_test = np.unique(y_test_oversampled_extreme, return_counts=True)\n",
    "num_class_0_oversampled_test = counts_oversampled_test[unique_oversampled_test == 0][0]\n",
    "num_class_1_oversampled_test = counts_oversampled_test[unique_oversampled_test == 1][0]\n",
    "\n",
    "print(\"Data Latih ADASYN Extreme:\")\n",
    "print(f\"Jumlah data latih: {len(y_train_oversampled_extreme)}\")\n",
    "print(f\"Jumlah kelas 0: {num_class_0_oversampled_train}\")\n",
    "print(f\"Jumlah kelas 1: {num_class_1_oversampled_train}\")\n",
    "print(\"\\nData Uji ADASYN Extreme:\")\n",
    "print(f\"Jumlah data uji: {len(y_test_oversampled_extreme)}\")\n",
    "print(f\"Jumlah kelas 0: {num_class_0_oversampled_test}\")\n",
    "print(f\"Jumlah kelas 1: {num_class_1_oversampled_test}\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# Menghitung jumlah kelas 0 dan 1 pada PCA-KMeans (data latih)\n",
    "unique_pca_kmeans_train, counts_pca_kmeans_train = np.unique(y_train_pca_kmeans_extreme, return_counts=True)\n",
    "num_class_0_pca_kmeans_train = counts_pca_kmeans_train[unique_pca_kmeans_train == 0][0]\n",
    "num_class_1_pca_kmeans_train = counts_pca_kmeans_train[unique_pca_kmeans_train == 1][0]\n",
    "\n",
    "# Menghitung jumlah kelas 0 dan 1 pada PCA-KMeans (data uji)\n",
    "unique_pca_kmeans_test, counts_pca_kmeans_test = np.unique(y_test_pca_kmeans_extreme, return_counts=True)\n",
    "num_class_0_pca_kmeans_test = counts_pca_kmeans_test[unique_pca_kmeans_test == 0][0]\n",
    "num_class_1_pca_kmeans_test = counts_pca_kmeans_test[unique_pca_kmeans_test == 1][0]\n",
    "\n",
    "print(\"Data Latih PCA-KMeans Extreme:\")\n",
    "print(f\"Jumlah data latih: {len(y_train_pca_kmeans_extreme)}\")\n",
    "print(f\"Jumlah kelas 0: {num_class_0_pca_kmeans_train}\")\n",
    "print(f\"Jumlah kelas 1: {num_class_1_pca_kmeans_train}\")\n",
    "print(\"\\nData Uji PCA-KMeans Extreme:\")\n",
    "print(f\"Jumlah data uji: {len(y_test_pca_kmeans_extreme)}\")\n",
    "print(f\"Jumlah kelas 0: {num_class_0_pca_kmeans_test}\")\n",
    "print(f\"Jumlah kelas 1: {num_class_1_pca_kmeans_test}\")\n",
    "print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menetapkan bentuk input dan jumlah kelas berdasarkan fitur dan target untuk ADASYN\n",
    "input_shape_adasyn = X_train_oversampled_extreme.shape[1:]\n",
    "num_classes_adasyn = y_oversampled_one_hot_extreme.shape[1]  # Disesuaikan untuk mendapatkan jumlah kelas secara dinamis\n",
    "y_train_oversampled_one_hot = tf.keras.utils.to_categorical(y_train_oversampled_extreme, num_classes_adasyn)\n",
    "y_test_oversampled_one_hot = tf.keras.utils.to_categorical(y_test_oversampled_extreme, num_classes_adasyn)\n",
    "\n",
    "# Menetapkan bentuk input dan jumlah kelas berdasarkan fitur dan target untuk PCA-KMeans\n",
    "input_shape_pca_kmeans = X_train_pca_kmeans_extreme.shape[1:]\n",
    "num_classes_pca_kmeans = y_pca_kmeans_one_hot_extreme.shape[1]  # Disesuaikan untuk mendapatkan jumlah kelas secara dinamis\n",
    "y_train_pca_kmeans_one_hot = tf.keras.utils.to_categorical(y_train_pca_kmeans_extreme, num_classes_pca_kmeans)\n",
    "y_test_pca_kmeans_one_hot = tf.keras.utils.to_categorical(y_test_pca_kmeans_extreme, num_classes_pca_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLP model for ADASYN\n",
    "model_adasyn = create_mlp_model(input_shape_adasyn, num_classes_adasyn)\n",
    "\n",
    "# Compile the model with Focal Loss\n",
    "model_adasyn.compile(optimizer='adam',\n",
    "                     loss=focal_loss(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Create the MLP model for PCA-KMeans\n",
    "model_pca_kmeans = create_mlp_model(input_shape_pca_kmeans, num_classes_pca_kmeans)\n",
    "\n",
    "# Compile the model with Focal Loss\n",
    "model_pca_kmeans.compile(optimizer='adam',\n",
    "                         loss=focal_loss(),\n",
    "                         metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 15)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               2048      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10434 (40.76 KB)\n",
      "Trainable params: 10434 (40.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.8440 - val_loss: 0.0158 - val_accuracy: 0.9095\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9245 - val_loss: 0.0118 - val_accuracy: 0.9302\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9354 - val_loss: 0.0123 - val_accuracy: 0.9324\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9455 - val_loss: 0.0100 - val_accuracy: 0.9477\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9471 - val_loss: 0.0105 - val_accuracy: 0.9422\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9520 - val_loss: 0.0096 - val_accuracy: 0.9509\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9525 - val_loss: 0.0088 - val_accuracy: 0.9575\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9517 - val_loss: 0.0080 - val_accuracy: 0.9651\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9547 - val_loss: 0.0081 - val_accuracy: 0.9662\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9566 - val_loss: 0.0089 - val_accuracy: 0.9629\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9599 - val_loss: 0.0079 - val_accuracy: 0.9618\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9610 - val_loss: 0.0077 - val_accuracy: 0.9629\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9588 - val_loss: 0.0094 - val_accuracy: 0.9531\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9640 - val_loss: 0.0076 - val_accuracy: 0.9651\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9635 - val_loss: 0.0074 - val_accuracy: 0.9673\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9635 - val_loss: 0.0068 - val_accuracy: 0.9673\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9626 - val_loss: 0.0079 - val_accuracy: 0.9651\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9648 - val_loss: 0.0075 - val_accuracy: 0.9673\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9648 - val_loss: 0.0072 - val_accuracy: 0.9662\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9656 - val_loss: 0.0080 - val_accuracy: 0.9586\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9678 - val_loss: 0.0076 - val_accuracy: 0.9564\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9654 - val_loss: 0.0081 - val_accuracy: 0.9673\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9662 - val_loss: 0.0066 - val_accuracy: 0.9695\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9675 - val_loss: 0.0083 - val_accuracy: 0.9564\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9624 - val_loss: 0.0073 - val_accuracy: 0.9618\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9673 - val_loss: 0.0073 - val_accuracy: 0.9673\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9665 - val_loss: 0.0067 - val_accuracy: 0.9695\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9675 - val_loss: 0.0098 - val_accuracy: 0.9477\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9670 - val_loss: 0.0070 - val_accuracy: 0.9684\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9703 - val_loss: 0.0076 - val_accuracy: 0.9575\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9700 - val_loss: 0.0067 - val_accuracy: 0.9706\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9716 - val_loss: 0.0066 - val_accuracy: 0.9673\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9716 - val_loss: 0.0075 - val_accuracy: 0.9640\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9716 - val_loss: 0.0109 - val_accuracy: 0.9509\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9705 - val_loss: 0.0073 - val_accuracy: 0.9684\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9708 - val_loss: 0.0072 - val_accuracy: 0.9651\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9703 - val_loss: 0.0084 - val_accuracy: 0.9520\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9695 - val_loss: 0.0064 - val_accuracy: 0.9684\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9749 - val_loss: 0.0066 - val_accuracy: 0.9727\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9735 - val_loss: 0.0066 - val_accuracy: 0.9695\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9733 - val_loss: 0.0064 - val_accuracy: 0.9651\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9746 - val_loss: 0.0110 - val_accuracy: 0.9520\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9656 - val_loss: 0.0067 - val_accuracy: 0.9749\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9752 - val_loss: 0.0071 - val_accuracy: 0.9684\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9730 - val_loss: 0.0062 - val_accuracy: 0.9716\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9749 - val_loss: 0.0069 - val_accuracy: 0.9662\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9768 - val_loss: 0.0058 - val_accuracy: 0.9727\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9755 - val_loss: 0.0056 - val_accuracy: 0.9727\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 0.9768 - val_loss: 0.0070 - val_accuracy: 0.9618\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9752 - val_loss: 0.0062 - val_accuracy: 0.9673\n",
      "36/36 [==============================] - 0s 874us/step - loss: 0.0114 - accuracy: 0.9721\n",
      "Test Loss (ADASYN) Extreme: 0.011356360279023647, Test Accuracy (ADASYN) Extreme: 0.9721011519432068\n",
      "36/36 [==============================] - 0s 864us/step\n",
      "Classification Report (ADASYN) Extreme:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       699\n",
      "           1       0.96      0.97      0.96       448\n",
      "\n",
      "    accuracy                           0.97      1147\n",
      "   macro avg       0.97      0.97      0.97      1147\n",
      "weighted avg       0.97      0.97      0.97      1147\n",
      "\n",
      "Confusion Matrix (ADASYN) Extreme:\n",
      " [[680  19]\n",
      " [ 13 435]]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 13)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10178 (39.76 KB)\n",
      "Trainable params: 10178 (39.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 250ms/step - loss: 0.0337 - accuracy: 0.4167 - val_loss: 0.0335 - val_accuracy: 0.8333\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0216 - accuracy: 0.7292 - val_loss: 0.0235 - val_accuracy: 0.9167\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.3109e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.5103e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.1022e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5.0901e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.3010e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.5823e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.1626e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.7272e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.4041e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.1386e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7316e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5910e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4591e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3409e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2427e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1566e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0911e-04 - accuracy: 1.0000 - val_loss: 9.9852e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0146e-04 - accuracy: 1.0000 - val_loss: 9.8188e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.5515e-05 - accuracy: 1.0000 - val_loss: 9.6533e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.0595e-05 - accuracy: 1.0000 - val_loss: 9.5201e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 8.5134e-05 - accuracy: 1.0000 - val_loss: 9.4042e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.1343e-05 - accuracy: 1.0000 - val_loss: 9.2951e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 7.7461e-05 - accuracy: 1.0000 - val_loss: 9.1841e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.4025e-05 - accuracy: 1.0000 - val_loss: 9.0977e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.0120e-05 - accuracy: 1.0000 - val_loss: 9.0098e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 6.7173e-05 - accuracy: 1.0000 - val_loss: 8.9200e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.4904e-05 - accuracy: 1.0000 - val_loss: 8.8325e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.2036e-05 - accuracy: 1.0000 - val_loss: 8.7658e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.9614e-05 - accuracy: 1.0000 - val_loss: 8.7156e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.7453e-05 - accuracy: 1.0000 - val_loss: 8.6770e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.5242e-05 - accuracy: 1.0000 - val_loss: 8.5866e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.3347e-05 - accuracy: 1.0000 - val_loss: 8.4850e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5.1509e-05 - accuracy: 1.0000 - val_loss: 8.4008e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.9841e-05 - accuracy: 1.0000 - val_loss: 8.3322e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.8313e-05 - accuracy: 1.0000 - val_loss: 8.2889e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.6607e-05 - accuracy: 1.0000 - val_loss: 8.2458e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.5210e-05 - accuracy: 1.0000 - val_loss: 8.1962e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.3821e-05 - accuracy: 1.0000 - val_loss: 8.1516e-04 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0440 - accuracy: 0.8750\n",
      "Test Loss (PCA-KMeans) Extreme: 0.0439736545085907, Test Accuracy (PCA-KMeans) Extreme: 0.875\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Classification Report (PCA-KMeans) Extreme:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90         9\n",
      "           1       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.88        16\n",
      "   macro avg       0.91      0.86      0.87        16\n",
      "weighted avg       0.90      0.88      0.87        16\n",
      "\n",
      "Confusion Matrix (PCA-KMeans) Extreme:\n",
      " [[9 0]\n",
      " [2 5]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights for ADASYN\n",
    "class_weights_adasyn = {0: num_class_1_oversampled_train / num_class_0_oversampled_train, 1: 1.0}\n",
    "\n",
    "# Print model summary for ADASYN\n",
    "model_adasyn.summary()\n",
    "\n",
    "# Train the model for ADASYN with class weights\n",
    "history_adasyn = model_adasyn.fit(X_train_oversampled_extreme, y_train_oversampled_one_hot, epochs=50, batch_size=32,\n",
    "                                  validation_split=0.2, class_weight=class_weights_adasyn)\n",
    "# Evaluate the model on the test set for ADASYN\n",
    "test_loss_adasyn, test_acc_adasyn = model_adasyn.evaluate(X_test_oversampled_extreme, y_test_oversampled_one_hot)\n",
    "print(f'Test Loss (ADASYN) Extreme: {test_loss_adasyn}, Test Accuracy (ADASYN) Extreme: {test_acc_adasyn}')\n",
    "\n",
    "# Predict classes for the test set for ADASYN\n",
    "y_pred_probabilities_adasyn = model_adasyn.predict(X_test_oversampled_extreme)\n",
    "y_pred_adasyn = y_pred_probabilities_adasyn.argmax(axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test back to numerical values for ADASYN\n",
    "y_true_adasyn = np.array(y_test_oversampled_extreme)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for ADASYN\n",
    "report_adasyn = classification_report(y_true_adasyn, y_pred_adasyn)\n",
    "print(\"Classification Report (ADASYN) Extreme:\\n\", report_adasyn)\n",
    "\n",
    "# Confusion Matrix for ADASYN\n",
    "conf_matrix_adasyn = confusion_matrix(y_true_adasyn, y_pred_adasyn)\n",
    "print(\"Confusion Matrix (ADASYN) Extreme:\\n\", conf_matrix_adasyn)\n",
    "\n",
    "\n",
    "# Calculate class weights for PCA-KMeans\n",
    "class_weights_pca_kmeans = {0: num_class_1_pca_kmeans_train / num_class_0_pca_kmeans_train, 1: 1.0}\n",
    "\n",
    "# Print model summary for PCA-KMeans\n",
    "model_pca_kmeans.summary()\n",
    "\n",
    "# Train the model for PCA-KMeans with class weights\n",
    "history_pca_kmeans = model_pca_kmeans.fit(X_train_pca_kmeans_extreme, y_train_pca_kmeans_one_hot, epochs=50, batch_size=32,\n",
    "                                          validation_split=0.2, class_weight=class_weights_pca_kmeans)\n",
    "\n",
    "# Evaluate the model on the test set for PCA-KMeans\n",
    "test_loss_pca_kmeans, test_acc_pca_kmeans = model_pca_kmeans.evaluate(X_test_pca_kmeans_extreme, y_test_pca_kmeans_one_hot)\n",
    "print(f'Test Loss (PCA-KMeans) Extreme: {test_loss_pca_kmeans}, Test Accuracy (PCA-KMeans) Extreme: {test_acc_pca_kmeans}')\n",
    "\n",
    "# Predict classes for the test set for PCA-KMeans\n",
    "y_pred_probabilities_pca_kmeans = model_pca_kmeans.predict(X_test_pca_kmeans_extreme)\n",
    "y_pred_pca_kmeans = y_pred_probabilities_pca_kmeans.argmax(axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test back to numerical values for PCA-KMeans\n",
    "y_true_pca_kmeans = y_test_pca_kmeans_extreme.to_numpy()\n",
    "\n",
    "# Calculate precision, recall, and F1-score for PCA-KMeans\n",
    "report_pca_kmeans = classification_report(y_true_pca_kmeans, y_pred_pca_kmeans)\n",
    "print(\"Classification Report (PCA-KMeans) Extreme:\\n\", report_pca_kmeans)\n",
    "\n",
    "# Confusion Matrix for PCA-KMeans\n",
    "conf_matrix_pca_kmeans = confusion_matrix(y_true_pca_kmeans, y_pred_pca_kmeans)\n",
    "print(\"Confusion Matrix (PCA-KMeans) Extreme:\\n\", conf_matrix_pca_kmeans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
